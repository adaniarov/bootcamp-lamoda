Lamoda Review Tag Inference System - Project Structure
========================================================

Root Directory:
/Users/a.danyarov/.cursor/worktrees/lamoda-bootcamp/oez/
â”‚
â”œâ”€â”€ ðŸ“„ Configuration Files
â”‚   â”œâ”€â”€ .env.example              # Environment variables template
â”‚   â”œâ”€â”€ .gitignore                # Git ignore rules
â”‚   â”œâ”€â”€ pyproject.toml            # Project dependencies & metadata
â”‚   â”œâ”€â”€ poetry.lock               # Locked dependencies
â”‚   â””â”€â”€ Makefile                  # Build automation
â”‚
â”œâ”€â”€ ðŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                 # Main documentation
â”‚   â”œâ”€â”€ QUICKSTART.md             # 5-minute setup guide
â”‚   â”œâ”€â”€ MIGRATION_GUIDE.md        # Old â†’ New migration guide
â”‚   â”œâ”€â”€ REFACTORING_SUMMARY.md    # What changed & why
â”‚   â”œâ”€â”€ README_OPENAI.md          # OpenAI-specific docs
â”‚   â””â”€â”€ PROJECT_STRUCTURE.txt     # This file
â”‚
â”œâ”€â”€ ðŸ Source Code (src/)
â”‚   â”‚
â”‚   â”œâ”€â”€ __init__.py               # Main package exports
â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸ”Œ clients/               # LLM client implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # Protocol interface
â”‚   â”‚   â””â”€â”€ openai_client.py     # OpenAI API implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ ðŸŽ¯ core/                  # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tag_inference.py     # Main inference pipeline
â”‚   â”‚   â””â”€â”€ pipeline.py          # Batch processing pipelines
â”‚   â”‚
â”‚   â””â”€â”€ ðŸ› ï¸  utils/                # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data.py              # Data loading utilities
â”‚       â”œâ”€â”€ preprocessing.py     # Review preprocessing
â”‚       â”œâ”€â”€ postprocessing.py    # Tag postprocessing
â”‚       â”œâ”€â”€ prompt_builder.py    # LLM prompt construction
â”‚       â””â”€â”€ llm_executor.py      # LLM execution with retries
â”‚
â”œâ”€â”€ ðŸ“ Examples (examples/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mock_client.py           # Mock LLM client for testing
â”‚   â”œâ”€â”€ example_basic_inference.py
â”‚   â””â”€â”€ example_pipeline.py
â”‚
â”œâ”€â”€ ðŸ“Š Data (data/)
â”‚   â”œâ”€â”€ raw/                     # Raw data files
â”‚   â”‚   â””â”€â”€ lamoda_reviews.csv  # (your data here)
â”‚   â””â”€â”€ processed/               # Processed results
â”‚       â””â”€â”€ llm_tags_results.csv
â”‚
â”œâ”€â”€ ðŸ““ Notebooks (notebooks/)
â”‚   â”œâ”€â”€ 01 experiment.ipynb
â”‚   â”œâ”€â”€ 02 EDA.ipynb
â”‚   â”œâ”€â”€ 02 baseline-clustering-product-type.ipynb
â”‚   â”œâ”€â”€ 03 clustering.ipynb
â”‚   â””â”€â”€ lamoda_full_baseline.ipynb
â”‚
â”œâ”€â”€ ðŸ“ Other Directories
â”‚   â”œâ”€â”€ models/                  # Saved models
â”‚   â”œâ”€â”€ docs/                    # Additional documentation
â”‚   â”œâ”€â”€ reports/                 # Generated reports
â”‚   â”‚   â””â”€â”€ figures/            # Visualization outputs
â”‚   â””â”€â”€ references/             # Reference materials
â”‚
â””â”€â”€ ðŸš€ Scripts
    â”œâ”€â”€ run_pipeline_openai.py   # Main pipeline runner
    â””â”€â”€ test_imports.py          # Import validation tests


Key Files Explained:
====================

Configuration:
--------------
â€¢ .env.example          â†’ Template for environment variables (API keys, settings)
â€¢ src/config.py         â†’ Centralized configuration management
â€¢ pyproject.toml        â†’ Project dependencies and metadata

Core Functionality:
-------------------
â€¢ src/core/tag_inference.py    â†’ Main inference logic (preprocessing â†’ LLM â†’ postprocessing)
â€¢ src/core/pipeline.py         â†’ Batch processing for files and SKUs
â€¢ src/clients/openai_client.py â†’ OpenAI API integration
â€¢ src/clients/llm_client.py    â†’ Protocol for any LLM provider

Utilities:
----------
â€¢ src/utils/data.py            â†’ Load and parse CSV data
â€¢ src/utils/preprocessing.py   â†’ Clean and prepare reviews
â€¢ src/utils/postprocessing.py  â†’ Validate and clean LLM output
â€¢ src/utils/prompt_builder.py  â†’ Construct LLM prompts
â€¢ src/utils/llm_executor.py    â†’ Execute LLM calls with retry logic

Examples:
---------
â€¢ examples/mock_client.py              â†’ Test without API costs
â€¢ examples/example_basic_inference.py  â†’ Simple usage example
â€¢ examples/example_pipeline.py         â†’ Batch processing example

Entry Points:
-------------
â€¢ run_pipeline_openai.py  â†’ Main script to run pipeline
â€¢ examples/*.py           â†’ Example scripts for learning


Import Patterns:
================

# Simple imports from main package
from src import OpenAIClient, run_inference, Config

# Specific imports from subpackages
from src.clients import LLMClient, OpenAIClient
from src.core import run_inference, run_pipeline_for_file
from src.utils import prepare_reviews, postprocess_tags

# Example imports
from examples.mock_client import MockLLMClient


Typical Usage Flow:
===================

1. Configure (.env)
   â””â”€> Set OPENAI_API_KEY and other settings

2. Initialize Client
   â””â”€> client = OpenAIClient()

3. Prepare Data
   â””â”€> reviews = load_dataset("data.csv")

4. Run Inference
   â””â”€> tags = run_inference(reviews, client, golden_tags...)

5. Save Results
   â””â”€> results.to_csv("output.csv")


Production Features:
====================

âœ“ Environment-based configuration
âœ“ Protocol-based design (easy to swap LLM providers)
âœ“ Comprehensive logging
âœ“ Error handling with retries
âœ“ Type hints throughout
âœ“ Clean separation of concerns
âœ“ No code duplication
âœ“ Examples separate from production code
âœ“ No hardcoded secrets


Development Workflow:
=====================

1. Testing (no API costs):
   python -m examples.example_basic_inference

2. Small batch test (minimal API costs):
   python run_pipeline_openai.py --limit 5

3. Production run:
   python run_pipeline_openai.py

4. Custom configuration:
   python run_pipeline_openai.py --input my_data.csv --output results.csv --limit 100


For More Information:
======================

â€¢ Quick start:     See QUICKSTART.md
â€¢ Full docs:       See README.md
â€¢ Migration help:  See MIGRATION_GUIDE.md
â€¢ What changed:    See REFACTORING_SUMMARY.md

